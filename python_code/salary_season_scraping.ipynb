{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNdGgx8zjorSoy2ku0n7Oov",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/OliverGriffiths287/OliverGriffiths287.github.io/blob/main/python_code/salary_season_scraping.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l9gplC3b1K3_"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the URL of the page containing the salary data\n",
        "url = \"https://www.capology.com/uk/premier-league/salaries/2022-2023\"\n",
        "\n",
        "# Send a GET request to the URL to retrieve the page's HTML content\n",
        "req = requests.get(url)\n",
        "\n",
        "# Extract the text content of the page (HTML source)\n",
        "page_src = req.text\n",
        "\n",
        "# Find the starting index of the average salary section in the HTML content\n",
        "# The salary information is located within a specific element containing 'accounting.formatMoney(\"'\n",
        "start_index = page_src.index('$(\\'#salaries-avg\\').html(accounting.formatMoney(\"')\n",
        "\n",
        "# Slice the page source starting from the location of the average salary element\n",
        "page_src = page_src[start_index:]\n",
        "\n",
        "# Split the sliced HTML content by double quotes to isolate the salary value\n",
        "page_src = page_src.split('\"')\n",
        "\n",
        "# Extract the average salary value (second item in the split list) and assign it to 'avg'\n",
        "avg = page_src[1]\n",
        "\n",
        "# Print or return the average salary value\n",
        "avg"
      ],
      "metadata": {
        "id": "D3sR9Tfn1L3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract the HTML content of the page as text\n",
        "page_src = req.text\n",
        "\n",
        "# Split the page source to isolate the JSON-like data within 'var data = ...'\n",
        "# This step assumes there's only one occurrence of 'var data =' in the page source\n",
        "page_src = page_src.split(\"var data =\")[1]\n",
        "\n",
        "# Further split the result to exclude any trailing characters after the JSON data\n",
        "# We're aiming to end the data at the first occurrence of \";\\n\"\n",
        "page_src = page_src.split(\";\\n\")[0]\n",
        "\n",
        "# Clean the extracted data by removing the outer square brackets to prepare it for parsing\n",
        "page_src = page_src.replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "\n",
        "# Display the cleaned data\n",
        "page_src\n",
        "\n",
        "# Split the data into individual player records, using '{' as the delimiter\n",
        "# Each entry in 'players' represents data for one player\n",
        "players = page_src.split(\"{\")\n",
        "\n",
        "# Initialize an empty list to store each player's parsed data as dictionaries\n",
        "players_data = []\n",
        "\n",
        "# Loop through each player entry in 'players' to parse their information\n",
        "for player_text in players:\n",
        "    # Create an empty dictionary to store parsed fields for this player\n",
        "    parsed_player_data = {}\n",
        "\n",
        "    # Remove the trailing \"},\" from the player data for easier parsing\n",
        "    player_text = player_text.replace(\"},\", \"\")\n",
        "\n",
        "    # Replace any double newlines with single newlines to standardize formatting\n",
        "    player_text = player_text.replace(\"\\n\\n\", \"\\n\")\n",
        "# Extract the HTML content of the page as text\n",
        "page_src = req.text\n",
        "\n",
        "# Split the page source to isolate the JSON-like data within 'var data = ...'\n",
        "# This step assumes there's only one occurrence of 'var data =' in the page source\n",
        "page_src = page_src.split(\"var data =\")[1]\n",
        "\n",
        "# Further split the result to exclude any trailing characters after the JSON data\n",
        "# We're aiming to end the data at the first occurrence of \";\\n\"\n",
        "page_src = page_src.split(\";\\n\")[0]\n",
        "\n",
        "# Clean the extracted data by removing the outer square brackets to prepare it for parsing\n",
        "page_src = page_src.replace(\"[\", \"\").replace(\"]\", \"\")\n",
        "\n",
        "# Display the cleaned data\n",
        "page_src\n",
        "\n",
        "# Split the data into individual player records, using '{' as the delimiter\n",
        "# Each entry in 'players' represents data for one player\n",
        "players = page_src.split(\"{\")\n",
        "\n",
        "# Initialize an empty list to store each player's parsed data as dictionaries\n",
        "players_data = []\n",
        "\n",
        "# Loop through each player entry in 'players' to parse their information\n",
        "for player_text in players:\n",
        "    # Create an empty dictionary to store parsed fields for this player\n",
        "    parsed_player_data = {}\n",
        "\n",
        "    # Remove the trailing \"},\" from the player data for easier parsing\n",
        "    player_text = player_text.replace(\"},\", \"\")\n",
        "    # Split the player's data into individual fields based on newlines\n",
        "    player_fields = player_text.split(\"\\n\")\n",
        "\n",
        "    # Uncomment the following line to print each player's text if needed\n",
        "    # print(player_text)\n",
        "\n",
        "    # Loop through each field in the player's data to extract key-value pairs\n",
        "    for player_field in player_fields:\n",
        "        # Skip empty lines\n",
        "        if len(player_field) == 0:\n",
        "            continue\n",
        "        # Extract name, URL, and flag image URL if the field contains 'name'\n",
        "        elif 'name' in player_field:\n",
        "            # Get the link\n",
        "            parsed_player_data['url'] = player_field.split(\"href='\")[1].split(\"'\")[0]\n",
        "            # Get the flag image URL\n",
        "            parsed_player_data['flag_img_url'] = player_field.split(\"<img src='\")[1].split(\"'\")[0]\n",
        "            # Extract the player's name\n",
        "            parsed_player_data['name'] = player_field.split(\"loading='lazy'>\")[1].split(\"<\")[0]\n",
        "        # Extract monetary values if the field contains 'accounting.formatMoney'\n",
        "        elif \"accounting.formatMoney\" in player_field:\n",
        "            # Get the field key and corresponding salary value\n",
        "            field_key = player_field.split(\"'\")[1].split(\"'\")[0]\n",
        "            value = player_field.split('\"')[1].split('\"')[0]\n",
        "            parsed_player_data[field_key] = value\n",
        "        # Extract position if 'position' is in the field\n",
        "        elif \"position\" in player_field:\n",
        "            parsed_player_data['position'] = player_field.split('\"')[1].split('\"')[0]\n",
        "        # Extract age if 'age' is in the field\n",
        "        elif \"age\" in player_field:\n",
        "            parsed_player_data[\"age\"] = player_field.split('\"')[1].split('\"')[0]\n",
        "        # Extract country if 'country' is in the field\n",
        "        elif \"country\" in player_field:\n",
        "            parsed_player_data[\"country\"] = player_field.split('\"')[1].split('\"')[0]\n",
        "\n",
        "    # Append the parsed player data dictionary to the list of all players' data\n",
        "    players_data.append(parsed_player_data)\n",
        "\n",
        "# Display the final parsed data for the players\n",
        "players_data"
      ],
      "metadata": {
        "id": "7RB4yLyg1Q6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df = pd.DataFrame(players_data)\n",
        "df = df[[\"name\", \"weekly_gross_eur\"]]\n",
        "\n",
        "df['weekly_gross_eur'] = pd.to_numeric(df[\"weekly_gross_eur\"], errors=\"coerce\")\n",
        "\n",
        "df = df.query(\"weekly_gross_eur > 0\")\n",
        "df.to_csv(\"premier_league_salaries.csv\", index=False)\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "B792LgTa1bJZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DhNA-S5I1ig_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}